
#+TITLE: Controlling Your Environment
#+AUTHOR: Cristian Ruiz, Michael Mercier\newline INRIA - France
#+DATE: April 5, 2016 -- Reproducible Research Webinar \mylogos
#+STARTUP: beamer overview indent

#+OPTIONS: H:2 toc:nil \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+LaTeX_CLASS_OPTIONS: [11pt,xcolor=dvipsnames,presentation]
#+BEAMER_COLOR_THEME:
#+BEAMER_FONT_THEME:
#+BEAMER_HEADER:
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+BEAMER_INNER_THEME:
#+BEAMER_OUTER_THEME:
#+BEAMER_THEME: default
#+LATEX_CLASS: beamer

#+LATEX_HEADER: \PassOptionsToPackage{svgnames}{xcolor}
#+LATEX_HEADER: \let\AtBeginDocumentSav=\AtBeginDocument
#+LATEX_HEADER: \def\AtBeginDocument#1{}
#+LATEX_HEADER: \input{org-babel-style-preembule.tex}
#+LATEX_HEADER: \let\AtBeginDocument=\AtBeginDocumentSav
#+LATEX_HEADER: \usepackage{minted}

#+LATEX_HEADER: \let\tmptableofcontents=\tableofcontents
#+LATEX_HEADER: \def\tableofcontents{}
#+LATEX_HEADER:  \usepackage{color,soul}
#+LATEX_HEADER:  \definecolor{lightblue}{rgb}{1,.9,.7}
#+LATEX_HEADER:  \sethlcolor{lightblue}
#+LATEX_HEADER:  \let\hrefold=\href
#+LATEX_HEADER:  \renewcommand{\href}[2]{\hrefold{#1}{\SoulColor\hl{#2}}}
#+LATEX_HEADER: \newcommand{\muuline}[1]{\SoulColor\hl{#1}}
#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \newcommand\SoulColor{%
#+LATEX_HEADER:   \let\set@color\beamerorig@set@color
#+LATEX_HEADER:   \let\reset@color\beamerorig@reset@color}
#+LATEX_HEADER: \makeatother

#+BIND: org-latex-title-command ""



#+LATEX_HEADER: \def\mylogos{\\\vspace{1cm}\begin{center}\includegraphics[height=1.2cm]{logos/inr_logo_sans_sign_coul.png}\hspace{0.5cm}\insertlogo{\includegraphics[height=1.2cm]{logos/grid5000.png}}\hspace{0.5cm}\end{center}\vspace{-1cm}}

*
:PROPERTIES:
:UNNUMBERED: t
:END:

** People involved in preparing this talk

- Michael Mercier (Inria/Atos)
- Cristian Ruiz (Inria)
Grid5000, \structure{Kameleon}, Expo, \dots
\bigskip\bigskip

Thanks for the feedback of:
- Pierre Neyron (CNRS)
- Arnaud Legrand (CNRS)
- Olivier Richard (UGA)
- Lucas Nussbaum (Loria)

#+BEGIN_CENTER
Here is the pad for interactions:
#+LaTeX: \href{http://tinyurl.com/RRW-pad2}{http://tinyurl.com/RRW-pad2}
#+END_CENTER
* setup								   :noexport:

** Download beamer theme and logos

#+BEGIN_SRC sh
 mkdir theme
 wget https://raw.githubusercontent.com/camilo1729/latex-tools/master/beamer_theme/beamerthemeCristian.sty
 mv beamerthemeCristian.sty  theme/
 wget https://github.com/camilo1729/latex-tools/blob/master/logos/grid5000.png
 wget https://github.com/camilo1729/latex-tools/blob/master/logos/inr_logo_sans_sign_coul.png
 mkdir logos
 mv *.png logos
#+END_SRC



* Why should we care?
#+BEGIN_LaTeX
\let\tableofcontents=\tmptableofcontents
\AtBeginSection[]
  {
     \begin{frame}<beamer>
     \frametitle{Outline}
     \tableofcontents[currentsection]
     \end{frame}
  }
#+END_LaTeX
#+LaTeX: \input{org-babel-document-preembule.tex}

** Motivations

*Reproducible research*: What does it mean? Watch the [[http://newstream.imag.fr/2016-03-07_Reproducible-Research_Arnaud-legrand.mp4][first webinar]] if
you need a reminder.\medskip

#+BEGIN_LaTeX
\begin{block}{Definition}
 A way to encapsulate all aspects of our in silico analysis in a manner that
would facilitate independent replication by another scientist
\end{block}
#+END_LaTeX

#+BEGIN_CENTER
  *Reproducibility is a cornerstone of scientific method*
#+END_CENTER

** Is code sufficient?
#+BEGIN_QUOTE
An article about computational science in a scientific publication
is not the scholarship itself, it is merely advertising of the scholarship.
The actual scholarship is *the complete software development environment* and
the complete set of instruction which generated the figures.
\flushright{-- David Donoho, 1998}
#+END_QUOTE

- *Making it available* is a great first step
- Making sure *others can rerun* it is an other move

** Problem statement
Experiment replication is not an easy task if you do not have it in mind from the
beginning:
\vspace{0.2cm}

#+BEGIN_QUOTE
The path from having a piece of software running on the programmer's own machine
to getting it running on someone else's machine is fraught with potential pitfalls
#+END_QUOTE

#+BEGIN_LaTeX
  \bottomcite{Philip J. Guo and Dawson Engler,
     \href{http://www.pgbovine.net/publications/CDE-create-portable-Linux-packages-short-paper_USENIX-2011.pdf}
    {\textit{CDE: Using System Call Interposition to Automatically Create Portable Software Packages}},
    USENIX LISA Conference,2011}
#+END_LaTeX
\bigskip

In reproducible research, scientists should care about both the
experiments and the analysis:
  - All the artifacts (input/outputs files)
  - The source code
  - Documentation on how to compile, install and run

Still, several problems may prevent someone to rerun an experiment


** Dependencies and compilation problems
- Unresolved dependencies :: \quad
  #+BEGIN_LaTeX
  \begin{center}
    \includegraphics[scale=0.25]{figures/Dependency.png}
  \end{center}
  #+END_LaTeX
- Compilation errors :: \quad
  #+BEGIN_LaTeX
  \begin{center}
    \includegraphics[scale=0.25]{figures/Compilation_error.png}
  \end{center}

  \bottomcite{Collberg, Christian \textit{et Al.},
     \href{http://reproducibility.cs.arizona.edu/v2/RepeatabilityTR.pdf}{\textit{Measuring Reproducibility in Computer Systems Research}},\\
     \url{http://reproducibility.cs.arizona.edu/}\qquad 2014,2015}
  #+END_LaTeX

     Less than 50% of experimental setups of papers submitted ACM
     conferences and journals could be built

** Other technical issues


- Portability issues :: E.g., BOINC had to rely on homogeneous
     redundancy to protect against numerical instabilities (OS,
     hardware, ...).

- Imprecise documentation ::
  "/I have no clue about how to install it, configure it or run it!/"

- Dependency Hell ::
  "/I can't install this dependency package without breaking my entire system/"
- Code rote ::
  "/This dependency package version is buggy! What was the version that was used to run the experiment in the first place?!?/"

#+BEGIN_LaTeX
  \bottomcite{Carl Boettiger,
     \href{http://www.carlboettiger.info/assets/files/pubs/10.1145/2723872.2723882.pdf}{\textit{An introduction to Docker for reproducible research}},
    ACM SIGOPS Operating Systems Review,2015}
#+END_LaTeX

** Cultural challenges

- Efforts are *not rewarded* by the current academic research and funding environment
- Software vendors tend to protect their markets through *proprietary* formats and interfaces
- Investigators naturally tend to want to own and *control* their research tools
- Even the most generalized software will not be able to meet the *specific needs* of every researcher in a field
- The need to derive and *publish* results *as quickly as possible* precludes the often slower standards-based development path

#+BEGIN_LaTeX
  \bottomcite{J. T. Dudley and A. J. Butte,
     \href{http://www.nature.com/nbt/journal/v28/n11/pdf/nbt1110-1181.pdf}{\textit{In silico research in the era of cloud computing}},
     Nature Biotechnology, 2010}
#+END_LaTeX

** Disseminating science software

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.4]{figures/CDE_author_user.pdf}
\end{figure}
#+END_LaTeX

** Disseminating science software

#+BEGIN_LaTeX
\begin{center}
  \includegraphics[scale=0.7]{figures/virtual_appliances.pdf}
\end{center}
#+END_LaTeX

- *Raw data and code*: rely on the published paper for documentation
- *Extensive documentation*: it may still require certain skills
- Adopt a *controlled environment*: e.g., rely on a scientific workflow
- Use *virtual machines* to capture and publish code, data and experimental environment

** Everywhere there is code, you need an environment

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.9]{figures/experiment_workflow.pdf}
\end{figure}
#+END_LaTeX

** Why should I take care of my experiment environment?
_For myself_:
  - Be able to reproduce my own experiment later
  - Improve my *productivity* (when preparing articles, PhD, rebuttals, \dots)
  - Be able to *scale* my experiment on other machines
  - *Facilitate* experiment extensions and modifications
  - Be a better scientist by doing better science $\winkey$

_For other people_: my students, my colleagues, my peers, \dots
  - Allow them to reproduce my experiment and *corroborate* (or not) my results
  - Allow them to base their research on my research and *extend*

_For everyone else_:
  - Improve knowledge sharing
  - Increase collaboration possibilities
  - *Do better science!*

** Controlling your environment

One way to go is to take care of your experimental environment

There are mainly _two approaches_:
- *Preserving the mess* by capturing the already set up environment
- *Encourage cleanliness* with several options:
   - Using a constrained environment
   - Building your own environment

 See [[http://ccl.cse.nd.edu/research/papers/techniques-ipres-2015.pdf][Preserve the Mess or Encourage Cleanliness?]] (Thain et al., 2015)

*** Constraint for simplicity, complexity for freedom
Each of them have different levels of constraint and flexibility:
    - The more constrained your environment is, the more simple it is
    - Freedom comes with responsibility

* What is an environment?
** Environment definition

#+BEGIN_LaTeX
\begin{block}{Definition (in our case)}
   An environment is a \uline{set of tools and materials} that
   permits a \uline{complete reproducibility} of a \uline{part or of the whole
   experiment process}.
\end{block}\medskip
#+END_LaTeX

   Can be numerous or unique depending on the experiment workflow:
   - Experiment environments
     - local, on a testbed, on a dedicated server,\dots
   - Analysis environments
     - Usually a unique local environment

   The whole environment contains both *hardware and software information*

** Hardware
Necessary when we carry out performance measures

Tools to capture hardware configuration:
  - =dmidecode=
  - hwloc (=lstopo=)
  - ls* tools (lsblk, lshw, lspci, lsmod,\dots)
  - proprietary tools (bios, nvidia,\dots)
  - Testbeds hardware description API (Grid'5000, Chameleon)

*** The hardware is not shareable
    As it is not shareable the *hardware environment needs to be documented*
    as exhaustively as possible.

    Of course it depends on how the results
    of experiments are affected by the underlying hardware.

** Software

Different types of environment:
*** Very succinct (usually what is provided, if provided...)                                      :B_definition:
:PROPERTIES:
:BEAMER_env: alertblock
:END:
- minimal description in a mail
- README in a git repository
- small documentation

*** Partial
:PROPERTIES:
:BEAMER_env: definition
:END:
- bundle of the experiment tool and it dependencies
- linux container image
*** Full
:PROPERTIES:
:BEAMER_env: example
:END:
A complete environment backup with the operating system included
- Virtual machine
- A complete system image

** Virtual environments: important notions

One of the role of the OS is to provide *isolation* with the host
- A virtual environment can only use a limited part of the resources:
      - filesystem
      - memory/cpu/disk/network
- Has his own software stack $\Rightarrow$ clean dependencies


By the way:
- What is a container? ::  An isolated part of the system that shares the
  operating system kernel
- What is a virtual machine? :: A full system image that shares the
     system hardware with your guest OS though an hypervisor

** VM vs container

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.2]{figures/docker-vm-container.png}
\end{figure}
#+END_LaTeX

** Types of environments

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.7]{figures/types_of_environments.pdf}
\end{figure}
#+END_LaTeX

* First approach: use a Constrained environment
** Use of third party environments
Environment build, specialized, controlled, versioned by somebody else:

*** thrid party                                                     :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:


- Activepapers (Beta)
  - Python or JVM based language
- SageMathCloud
  - Use Jupyter
    - Julia, Python, R, Haskell, Ruby...
    - 40 languages (partly) supported

Sharing is easy but you have to stick to what the environment provides

*** image                                                           :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.4
:END:
#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.15]{figures/SageMath.png}
\end{figure}
#+END_LaTeX

** Use a controlled environment as a base

Start your experimental setup in a controlled environment *from the beginning*

- Clean install system in a virtual environment
- Default Testbed (Grid'5000, Cloudlab, Chameleon) environments
- Software appliances market place (e.g., TURNKEY[fn:turnkey], Cloud Market[fn:amazon])

*This encourage cleanliness*:\\
  Your environment is controlled _(you start from a clean system)_

[fn:turnkey] http://www.turnkeylinux.org
[fn:amazon] http://www.thecloudmarket.com

*** Drawbacks
  Nothing is responsible for tracking the modifications applied in
  this environment\\
  *You don't know what is inside the box* $\frowny$

* Second approach: Capturing an environment
** Capturing an environment
   Several approaches for capturing your environment:
   - Export *everything*
     - Kernel + Libraries + Application
     - Heavy but safe
   - Capture *only what is needed* to run on a similar system
     - Libraries (only dependencies) + App
     - Lightweight but can be partial

** Copying your experiment environment
   A simple capture of an environment is a *complete copy* of it.

   It depends on what your environment is:
   1. On a classical local machine:
      - Problem: A simple backup bundle is not easily usable by others
      - Partial solution: Clone your hard drive to a VM (excluding personal data)

   2. On a VM or any Copy-on-write environment use the instant
        snapshot capability
      - Faster and simpler backup
      - VM need to be used from the beginning (mentioned previously)

   3. On a testbed machine use the provided snapshot mechanism

   In either case *sharing is complicated*
     - Huge environment images of several Gigabytes are common
     - Need a dedicated place to store them (a repository or some market place)

  *You still don't know what is inside the box* $\frowny$ \smallskip

#+BEGIN_LaTeX
  \bottomcite{J. T. Dudley and A. J. Butte,
     \href{http://www.nature.com/nbt/journal/v28/n11/pdf/nbt1110-1181.pdf}{\textit{In silico research in the era of cloud computing}},
     Nature Biotechnology\qquad 2010}
#+END_LaTeX

** Capture only what is needed
Use a *tracking tool* to *capture only what is necessary*

- Instrumenting a run of your experiment to catch every used material
   - Binaries/Scripts (experiment.py, Python 2.7)
   - Configuration files (conf.yaml)
   - Libraries (libc, numpy, matplotlib)
   Then create a *compressed bundle*

- Rerun the experiment on another machine:
   1) Import the provided bundle
   2) Initialize the environment (depends on the tools...)
   3) Rerun the exact same experiment

*Capture is not foolproof*:
   - Running with only one set of parameters is not enough
   - More risk to miss something $\frowny$

Less messy than virtual environment copy $\smiley$
but *it is not easy to modify it* to extend an experiment $\frowny$


** Capture tools

Existing tools:
- [[http://www.pgbovine.net/cde.html][CDE]] (Guo et al., 2011)
  - First to bring the idea
  - Seems not maintained since 2013
- *[[https://vida-nyu.github.io/reprozip/][ReproZip]]* (Freire et al., 2013)
  - One tool to trace and pack
  - Several tools to unpack and run (install package, chroot, docker,
    vagrant)
  - More during the demo $\smiley$
- [[http://reproducible.io/][CARE]] (Janin et al., 2014)
  - Only for experts
  - Seems unmaintained since 2014
- Parrot
  - Limited to the Parrot filesystem...

* Third approach: Building a complete environment
** Environment generation (some facts)
- If you're moving a computation to a new system,
  it should be simple and straightforward to set up the environment almost identical
  to that of the original machine
- A major challenge in reproducing computations is *installing the
  prerequisite software environment* $\frowny$
- Modern open computational science relies on complex software stacks
- So, it is necessary to know:
   - How was it built?
   - What does it contains?
   - How can I modify it to extend the experiment?


** How is software installed and configured?

*** Source code compilation

  #+BEGIN_SRC sh
   $ tar -xzf pdt-3.19.tar.gz && cd pdtoolkit-3.19/
   $./configure -prefix=/usr/local/pdt-install
   $ make clean install
  #+END_SRC
- Need to install all dependencies by hand
- Some skills are required
*** Package manager
A PM is a collection of software tools that *automates* the process of
*installing*, *upgrading*, *configuring*, and *removing* computer programs for
a computer's operating system in a consistent manner

- Examples in the Linux world: APT, yum, pacman, Nix \dots

- There also exists package managers for programming languages:
  Bundler, CPAN, CRAN, EasyInstall, Go Get, Maven, pip, RubyGems, \dots


** The DevOps Approach

- Dev = Development, Ops= (System) operation
- *You have a pile of crusty code that's hard to install*
- And documenting how to install it is almost as hard! $\smiley$
- Why not develop scripts that reliably install your toolset?
  - Because that sounds hard ? $\winkey$
  - But it's more fun than writing documentation!

Use all the good things that software engineering has created along
decades for ensuring *isolation* and *reproducibility*
** Creating recipes: text based description

- README
- Shell scripts
- Configuration management tools:
  automate software configuration and installation
  - Software stacks can be easily transportable
  - Some CM tools: Puppet, Salt, Ansible
  - A lot of work has to be done to write recipes $\frowny$


** DevOps response: Docker for deployment

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.3]{figures/eliminates-matrix-from-hell.png}
\end{figure}
#+END_LaTeX

Any application can be easily moved through different environments

** DevOps response: Docker for deployment

- Docker is an open-source engine that automates the deployment
  of any application as a lightweight, portable, self-sufficient container
  that will run virtually anywhere
- Docker tries to achieve deterministic builds by isolating your service,
  building it from a snapshotted OS and running imperative steps on top of it

- *Dependcy hell*: Docker works with images that consume minimal disk space, are
  versioned, archiveable, and shareable (DockerHub) 

- *Dockerfiles*: resolving imprecise documentation

# #+BEGIN_LaTeX
# \begin{figure}[!h]
#   \center
# \includegraphics[scale=0.1]{figures/docker-vm-container.png}
# \end{figure}
# #+END_LaTeX

 

** DevOps response: Vagrant for building

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.4]{figures/vagrant_explained.pdf}
\end{figure}
#+END_LaTeX

- It automates the build of development environment using a base environment called *box* and
  a series of text-based instructions

** DevOps response: Vagrant for building

- Researchers write text-based configuration files that provide instruction to build virtual machines
- *Somehow solves way the problem of sharing a VM*. Since these files are small,
  researchers can easily share them and track different versions via
  source-control repositories
- *VMs are not seen as black boxes anymore*
- Researchers can automate the process of building and configuring virtual machines
- It is possible to use different providers: EC2, Virtualbox, VMware, Docker, etc \dots

** Reproducible builds: a functional package management\hspace{.3em}(Nix)\hspace{-5em}

- *Apply functional model to packaging*
#+BEGIN_QUOTE
A package is the output of a function that is deterministic (it
depends only on a function inputs, without any side effects)
#+END_QUOTE

- The principle: *two independent runs of a given build process for a given set of inputs should return the same value*
- Functional hash-based immutable package management
- Isolated build
- Deterministic
- No dependency hell

** Reproducible builds: Nix workflow

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.7]{figures/Nix_workflow.pdf}
\end{figure}
#+END_LaTeX

** Environment generation
#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.6]{figures/Environment_creation.pdf}
\end{figure}
#+END_LaTeX



** Reconstrucability
An experimental setup $E'$ is *reconstructable* if the following three
facts hold:
1. Experimenters have access to the original base experimental setup \(E\).
2. Experimenters know exactly the sequence of actions \(\langle A_{1}, A_{2}, A_{3},
   ..., A_{n}\rangle \) that produced \(E'\).
3. \bf Experimenters are able to change some action \(A_{i}\) and
   successfully re-construct an experimental setup \(E''\)

#+BEGIN_LaTeX
\vspace{0.5cm}
  \bottomcite{Ruiz, Cristian et Al.,
     \href{http://dl.acm.org/citation.cfm?id=2723883}{\textit{Reconstructable Software Appliances with Kameleon}}
    ACM SIGOPS Operating Systems Review,2015}
#+END_LaTeX

** Reconstrucability
#+BEGIN_LaTeX

It can be expressed as \(E' = f(E,\langle A_{i} \rangle ) \)
where \( f \) applies \(\langle A_{i} \rangle \) to \(E\) to
derive the experimental setup \(E'\).


Few cases where this hypothesis \alert{does not hold}:
\begin{itemize}
  \item An action \(A_{i}\) is composed of sub-tasks that are executed concurrently making the process not deterministic.
        For example: \texttt{Makefile} \texttt{-j}
  \item packages are validated based on timestamps (Debian 8)
  \item The compiler may purposedly non-deterministic (e.g., \emph{stack-smashing protector} canaries)
  \item Leaked information from the host: \texttt{hostname}, \texttt{/proc/cpuinfo}
\end{itemize}
#+END_LaTeX

_Additional problems_:
- Accessing the same base setup \(E\)
- \bgroup\bf Software used is not available anymore\egroup



** Dealing with software availability (Debian Snapshot)
The Debian community is quite active on the reproducibility front.
- It's an archive that allows to access old packages based on dates
  and version numbers
- It provides a valuable resource for tracking down when regressions
  were introduced, or *for providing a specific environment that a
  particular application may require to run*
- Only concerns software that is packaged $\frowny$

** Kameleon: Reconstructable Appliance Generator

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.6]{figures/Kameleon_explained.pdf}
\end{figure}
#+END_LaTeX
** Kameleon Features
- Easy to use  $\leadsto$ *structured language* based on few constructs and
  which relies on shell commands
- Allows shareability thanks to the hierarchical structure of *recipes*
  and the *extend mechanism*
- Kameleon supports the build process by providing debugging
  mechanisms such as *interactive shell sessions*, *break-points* and
  *checkpointing*
- Allows the easy integration of providers using the same language for
  the recipes
- *Persistent cache* makes  *reconstructability* a reality

* Demo time
** Docker
Docker advantages for reproducible research:

- Integrating into local development environments
- Modular reuse
- Portable environments
- Public repositories for sharing
- Versioning

#+BEGIN_LaTeX
  \bottomcite{Carl Boettiger,
     \href{http://www.carlboettiger.info/assets/files/pubs/10.1145/2723872.2723882.pdf}{\textit{An introduction to Docker for reproducible research}},
    ACM SIGOPS Operating Systems Review,2015}
#+END_LaTeX

** Docker advantages

- Portable computation & sharing

#+BEGIN_SRC sh
 $ docker export container-name > container.tar
 $ docker push username/r-recommended
#+END_SRC

- Re-usable modules
#+BEGIN_SRC sh
$ docker run -d --name db training/postgres
$ docker run -d -P --link db:bd training/webapp \
   python app.py
#+END_SRC

- Versioning

#+BEGIN_SRC sh
$ docker history r-base
$ docker tag  d7e5801bb7ac ttimbers/mmp-dyf-skat:latest
#+END_SRC

** A complete use case: Batsim

TODO: Add link to the demo

* Conclusion
** Conclusion
Reproducibility is easier when you have it in mind from the beginning

- Choose your tools :: Reproducibility brings some complexity but
     more and more tools to manage this complexity for you
- Provide environments :: Whatever the environment quality you
     provide, it is better than no environment at all $\winkey$
- Better if you provide the recipe :: Providing experiment environment
     is good. Providing the recipe to build this environment is better!
** Conclusion
#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.4]{figures/Conclusion_software_dis.pdf}
\end{figure}
#+END_LaTeX


* Emacs Setup                                                      :noexport:
This document has local variables in its postembule, which should
allow org-mode to work seamlessly without any setup. If you're
uncomfortable using such variables, you can safely ignore them at
startup. Exporting may require that you copy them in your .emacs.

# Local Variables:
# eval:    (setq org-latex-listings 'minted)
# eval:    (setq org-latex-minted-options '(("bgcolor" "Apricot") ("numbersep" "5pt")))
# eval:    (setq org-latex-pdf-process '("pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"))
# End:
